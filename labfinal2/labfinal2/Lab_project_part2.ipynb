{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [*Lab Project Part 2*]() CNNs for Image Classification\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Guideline\n",
    "1. Aim:\n",
    "    - *Understand  the  basic  Image  Classification/Recognition  pipeline  and  the  data-driven  approach (train/predict stages).*\n",
    "    - *Get used to one of deep learning frameworks (e.g. PyTorch).*\n",
    "2. Prerequisite:\n",
    "    - *Familiar with python and relevant packages.*\n",
    "    - *Known the basic knowledge of Convolutional Neural Networks*\n",
    "\n",
    "### PyTorch versions\n",
    "we assume that you are using latest PyTorch version(>=1.4)\n",
    "\n",
    "### PyTorch Tutorial & Docs\n",
    "You can learn pytorch from the [tutorial link](https://pytorch.org/tutorials/). The Docs information can be searched at [Docs](https://pytorch.org/docs/stable/index.html). In this assignments, we wish you to form the basic capability of using one of the well-known frameworks for deep learning tasks.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 1: Image Classifiation on CIFAR 10\n",
    "### Install pytorch and run the given codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# referenced codes: https://pytorch.org/tutorials/\n",
    "# referenced codes: http://cs231n.stanford.edu/\n",
    "# referenced codes: https://cs.stanford.edu/~acoates/stl10/\n",
    "######################################################\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  *` Q2.1: test dataloader and show the images of each class  of CIFAR10`*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random training images \n",
    "#at least one of each class\n",
    "while True:\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "    if len(set(labels)) >= 10: break\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# print labels\n",
    "for i in range (4):\n",
    "    print(' '.join('%5s' % classes[labels[j]] for j in range(i*8, i*8+8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  *` Q2.2: Architecture understanding. Implement architecture of TwolayerNet and ConvNet.`*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwolayerNet(nn.Module):\n",
    "    # assign layer objects to class attributes\n",
    "    # nn.init package contains convenient initialization methods\n",
    "    # http://pytorch.org/docs/master/nn.html#torch-nn-init\n",
    "    def __init__(self,input_size ,hidden_size ,num_classes ):\n",
    "        '''\n",
    "        :param input_size: 3*32*32\n",
    "        :param hidden_size: decide by yourself e.g. 1024, 512, 128 ...\n",
    "        :param num_classes: \n",
    "        '''\n",
    "        super(TwolayerNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # flatten\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        scores = self.fc2(F.relu(self.fc1(x)))\n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    # Complete the code using LeNet-5\n",
    "    # reference: https://ieeexplore.ieee.org/document/726791\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.conv1(x))\n",
    "        x = F.avg_pool2d(x, 2, 2)\n",
    "        x = F.tanh(self.conv2(x))\n",
    "        x = F.avg_pool2d(x, 2, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## exmample. You can change and modify it if you like.\n",
    "## use the above defined trainloader directly and train the models \n",
    "def train(net, trainloader,epoch=1):\n",
    "    ###################### Define Loss function and optimizer\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=0.001)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net.to(device)\n",
    "    t_ls=[]\n",
    "    ############################### Training\n",
    "    for epoch in range(epoch):  # loop over the dataset multiple times \n",
    "        loss_ep = 0\n",
    "        net.train()\n",
    "        for x, l in trainloader:\n",
    "            x=x.to(device)\n",
    "            l=l.to(device)\n",
    "            net.zero_grad()\n",
    "\n",
    "            # Step 3. Run our forward pass.\n",
    "            tag_scores = net(x)\n",
    "            loss = loss_function(tag_scores, l)\n",
    "\n",
    "            loss_ep+=loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        print(\"Training data loss\", loss_ep)\n",
    "        t_ls.append(loss_ep)\n",
    "\n",
    "    print('Finished Training')\n",
    "    plt.title('Cross Entropy Loss {}'.format(type(net).__name__))\n",
    "    plt.xlabel('Epoch')\n",
    "    if torch.cuda.is_available():\n",
    "        t_ls = torch.tensor(t_ls, device = 'cpu') \n",
    "    plt.plot(t_ls.\n",
    "             numpy(),label=\"train\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Train Two-layer Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwolayerNet(3*32*32, 128, 10)\n",
    "train(model, trainloader, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train ConvNet - LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = ConvNet()\n",
    "train(model_cnn, trainloader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(net,testloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            net.eval()\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "            100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_class(net,testloader,classes):\n",
    "    class_correct = list(0. for i in range(len(classes)))\n",
    "    class_total = list(0. for i in range(len(classes)))\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            net.eval()\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "    for i in range(len(classes)):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Test Two-layer Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid(model,testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_class(model,testloader,classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test ConvNet - LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid(model_cnn,testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_class(model_cnn,testloader,classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  *` Q2.3: Preparation of training. Create Dataloader yourself and define Transform, optimizer.`*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *` Complement  CIFAR10_loader()`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  suggested reference: https://pytorch.org/tutorials/recipes/recipes/custom_dataset_transforms_loader.html?highlight=dataloader\n",
    "# functions to show an image\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CIFAR10_loader(Dataset):\n",
    "    ################################\n",
    "    # Todo: finish the code\n",
    "    ################################\n",
    "    def __init__(self,root,train=True,transform = None):\n",
    "        if train:\n",
    "            for i in range(5):\n",
    "                batch = self.unpickle(root+\"data_batch_\"+str(i+1))\n",
    "                temp_data = batch['data']\n",
    "                temp_labels = batch['labels']\n",
    "                if i == 0:\n",
    "                    self.data = temp_data\n",
    "                    self.labels = temp_labels\n",
    "                else:\n",
    "                    self.data = np.concatenate((self.data, temp_data), axis=0)\n",
    "                    self.labels = np.concatenate((self.labels, temp_labels), axis=0)\n",
    "        else:\n",
    "            batch = self.unpickle(root+\"test_batch\")\n",
    "            self.data = batch['data']\n",
    "            self.labels = batch['labels']\n",
    "        \n",
    "        self.data = self.reshaped_data(self.data)\n",
    "        self.transform = transform\n",
    "        self.length = len(set(self.labels))\n",
    "    \n",
    "    def unpickle(self, file):\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='latin1')\n",
    "        return dict\n",
    "    \n",
    "    def reshaped_data(self, data):\n",
    "        assert data.shape[1] == 3072\n",
    "        dim = np.sqrt(1024).astype(int)\n",
    "        r = data[:, 0:1024].reshape(data.shape[0], dim, dim, 1)\n",
    "        g = data[:, 1024:2048].reshape(data.shape[0], dim, dim, 1)\n",
    "        b = data[:, 2048:3072].reshape(data.shape[0], dim, dim, 1)\n",
    "        reshaped = np.concatenate([r,g,b], -1)\n",
    "        return reshaped\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        ################################\n",
    "        # Todo: finish the code\n",
    "        ################################\n",
    "        img = self.data[item]\n",
    "        label = self.labels[item]\n",
    "        label = torch.tensor(label, dtype=torch.int64)\n",
    "        #One-hot encoding\n",
    "        target = np.zeros((self.length))\n",
    "        target[label - 1] = 1\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose(\n",
    "    [transforms.ToPILImage(),\n",
    "     transforms.RandomHorizontalFlip(),\n",
    "     transforms.RandomVerticalFlip(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "class Adam:\n",
    "    def __init__(self, model_params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8):\n",
    "        self.model_params = list(model_params)\n",
    "        self.lr = lr\n",
    "        self.beta_1, self.beta_2 = betas\n",
    "        self.eps = eps\n",
    "        self.avg_grads = [torch.zeros_like(p) for p in self.model_params]\n",
    "        self.avg_sqr_grads = [torch.zeros_like(p) for p in self.model_params]\n",
    "        self.n_steps = 0\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        for param in self.model_params:\n",
    "            param.grad = None\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self):\n",
    "        for param, avg_grad, avg_sqr_grad in zip(self.model_params, \\\n",
    "                                                 self.avg_grads, \\\n",
    "                                                 self.avg_sqr_grads):\n",
    "            \n",
    "            self.n_steps += 1\n",
    "            avg_grad.mul_(self.beta_1).add_(param.grad * (1 - self.beta_1))\n",
    "            avg_sqr_grad.mul_(self.beta_2).add_(param.grad * param.grad * (1 - self.beta_2))\n",
    "            avg_grad_corrected = avg_grad.div(1 - self.beta_1 ** self.n_steps)\n",
    "            avg_sqr_grad_corrected = avg_sqr_grad.div(1 - self.beta_2 ** self.n_steps)\n",
    "            std = avg_sqr_grad_corrected.sqrt().add(self.eps)\n",
    "            param.sub_(self.lr * avg_grad_corrected / std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *` Train the ConvNet with CIFAR10_loader, transform and optimizer you implemented and compare the results`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader,epoch=1):\n",
    "    ###################### Define Loss function and optimizer\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=0.001)\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        optimizer = Adam(net.parameters())\n",
    "    net.to(device)\n",
    "    t_ls=[]\n",
    "    ############################### Training\n",
    "    for epoch in range(epoch):  # loop over the dataset multiple times \n",
    "\n",
    "        ################################\n",
    "        # Todo: finish the code\n",
    "        ################################\n",
    "        loss_ep = 0\n",
    "        net.train()\n",
    "        for x, l in trainloader:\n",
    "            x=x.to(device)\n",
    "            l=l.to(device)\n",
    "            net.zero_grad()\n",
    "\n",
    "            # Step 3. Run our forward pass.\n",
    "            tag_scores = net(x)\n",
    "\n",
    "            loss = loss_function(tag_scores, l)\n",
    "            \n",
    "            loss_ep+=loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        print(\"Training data loss\", loss_ep)\n",
    "        t_ls.append(loss_ep)\n",
    "\n",
    "    print('Finished Training')\n",
    "    plt.title('Cross Entropy Loss {}'.format(type(net).__name__))\n",
    "    plt.xlabel('Epoch')\n",
    "    if torch.cuda.is_available():\n",
    "        t_ls = torch.tensor(t_ls, device = 'cpu') \n",
    "    plt.plot(t_ls.numpy(),label=\"train\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call our dataloader\n",
    "path = \"C:/Users/silav/Downloads/labfinal2/data/cifar-10-batches-py/\"\n",
    "transformed_dataset = CIFAR10_loader(path, transform = transform_train)\n",
    "trainloader = DataLoader(transformed_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Training Two Layer Net\n",
    "two_layer_net = TwolayerNet(3*32*32, 128, 10)\n",
    "print('Training on Cifar10 using Two Layer Net')\n",
    "train(two_layer_net, trainloader, epoch=10)\n",
    "\n",
    "# Training ConvNet - LeNet-5\n",
    "model_cnn = ConvNet()\n",
    "print('Training on Cifar10 using ConvNet - LeNet-5')\n",
    "train(model_cnn, trainloader, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *` Q2.4 Setting up the hyperparameters.`*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *`Play with convNet and TwolayerNet, set up the hyperparameters and reach the accuracy as high as you can`*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Layer Net Hyperparameters pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_customization(net, trainloader, loss_function, optimizer, epoch=1):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net.to(device)\n",
    "    t_ls=[]\n",
    "    for epoch in range(epoch):  # loop over the dataset multiple times \n",
    "        loss_ep = 0\n",
    "        net.train()\n",
    "        for x, l in trainloader:\n",
    "            x=x.to(device)\n",
    "            l=l.to(device)\n",
    "            net.zero_grad()\n",
    "\n",
    "            # Step 3. Run our forward pass.\n",
    "            tag_scores = net(x)\n",
    "            loss = loss_function(tag_scores, l)\n",
    "\n",
    "            loss_ep+=loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        print(\"Training data loss\", loss_ep)\n",
    "        t_ls.append(loss_ep)\n",
    "\n",
    "    print('Finished Training')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters: Batch_size = 64, Loss_function = CrossEntropyLoss, Optimizer = Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwolayerNet(3*32*32, 64, 10)\n",
    "train_customization(model, trainloader, nn.CrossEntropyLoss(), optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001), 10)\n",
    "valid(model,testloader)\n",
    "valid_class(model,testloader,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "train_customization(model, trainloader, nn.CrossEntropyLoss(), optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001), 10)\n",
    "valid(model,testloader)\n",
    "valid_class(model,testloader,classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters: Batch_size = 128, Loss_function = CrossEntropyLoss, Optimizer = Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwolayerNet(3*32*32, 128, 10)\n",
    "train_customization(model, trainloader, nn.CrossEntropyLoss(), optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001), 10)\n",
    "valid(model,testloader)\n",
    "valid_class(model,testloader,classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters: Batch_size = 64, Loss_function = MultiMarginLoss, Optimizer = Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwolayerNet(3*32*32, 64, 10)\n",
    "train_customization(model, trainloader, nn.MultiMarginLoss(), optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001), 10)\n",
    "valid(model,testloader)\n",
    "valid_class(model,testloader,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "train_customization(model, trainloader, nn.MultiMarginLoss(), optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001), 10)\n",
    "valid(model,testloader)\n",
    "valid_class(model,testloader,classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters: Batch_size = 64, Loss_function = CrossEntropyLoss, Optimizer = Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwolayerNet(3*32*32, 64, 10)\n",
    "train_customization(model, trainloader, nn.CrossEntropyLoss(), optim.Adadelta(model.parameters(), lr=1.0, weight_decay=0.001), 10)\n",
    "valid(model,testloader)\n",
    "valid_class(model,testloader,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()train_customization(model, trainloader, nn.CrossEntropyLoss(), optim.Adadelta(model.parameters(), lr=1.0, weight_decay=0.001), 10)\n",
    "valid(model,testloader)\n",
    "valid_class(model,testloader,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.RandomErasing(),\n",
    "     transforms.ColorJitter(brightness=0.1, contrast=0.2, saturation=0, hue=0),\n",
    "     AddGaussianNoise(0.1, 0.08),\n",
    "     transforms.RandomCrop((120,120)),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwolayerNet(3*32*32, 64, 10)\n",
    "train_customization(model, trainloader, nn.CrossEntropyLoss(), optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001), 10)\n",
    "valid(model,testloader)\n",
    "valid_class(model,testloader,classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add two layer in each network we have already have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourlayerNet(nn.Module):\n",
    "    # assign layer objects to class attributes\n",
    "    # nn.init package contains convenient initialization methods\n",
    "    # http://pytorch.org/docs/master/nn.html#torch-nn-init\n",
    "    def __init__(self,input_size ,hidden_size_1, hidden_size_2, hidden_size_3 ,num_classes ):\n",
    "        '''\n",
    "        :param input_size: 3*32*32\n",
    "        :param hidden_size: decide by yourself e.g. 1024, 512, 128 ...\n",
    "        :param num_classes: \n",
    "        '''\n",
    "        super(FourlayerNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size_1 = hidden_size_1\n",
    "        self.hidden_size_2 = hidden_size_2\n",
    "        self.hidden_size_3 = hidden_size_3\n",
    "        self.num_classes = num_classes\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size_1)\n",
    "        self.fc2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
    "        self.fc3 = nn.Linear(hidden_size_2, hidden_size_3)\n",
    "        self.fc4 = nn.Linear(hidden_size_3, num_classes) \n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # flatten\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        scores = self.fc4(F.relu(x))\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FourlayerNet(3*32*32, 256, 128, 64, 10)\n",
    "train_customization(model, trainloader, nn.CrossEntropyLoss(), optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001), 10)\n",
    "valid(model,testloader)\n",
    "valid_class(model,testloader,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet_plus2(nn.Module):\n",
    "    # Complete the code using LeNet-5\n",
    "    # reference: https://ieeexplore.ieee.org/document/726791\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(ConvNet_plus2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 5)\n",
    "        self.conv4 = nn.Conv2d(32, 64, 5)\n",
    "        self.fc1   = nn.Linear(256, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.conv1(x))\n",
    "        x = F.tanh(self.conv2(x))\n",
    "        x = F.avg_pool2d(x, 2, 2)\n",
    "        x = F.tanh(self.conv3(x))\n",
    "        x = F.tanh(self.conv4(x))\n",
    "        x = F.avg_pool2d(x, 2, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = ConvNet_plus2()\n",
    "train(model_cnn, trainloader, 10)\n",
    "valid(model_cnn,testloader)\n",
    "valid_class(model_cnn,testloader,classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *` test the accuracy of ConvNet `*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = ConvNet_plus2()\n",
    "train(model_cnn, trainloader, 10)\n",
    "valid(model_cnn,testloader)\n",
    "valid_class(model_cnn,testloader,classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *`test the accuracy of TwolayerNet`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FourlayerNet(3*32*32, 256, 128, 64, 100)\n",
    "train_customization(model, trainloader, nn.CrossEntropyLoss(), optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001), 10)\n",
    "valid(model,testloader)\n",
    "valid_class(model,testloader,classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 2:  Finetuning the ConvNet\n",
    "### STL-10 DATASET\n",
    "> The provided network is trained on a different dataset named CIFAR-10 , which\n",
    "contains the images of 10 different object categories. The dataset we use throughout the assignment is a subset of STL-10 \n",
    "with larger sizes and different object classes. So, there is a discrepancy between the\n",
    "dataset we use to train (CIFAR-10) and test (STL-10) our network. One solution\n",
    "would be to train the whole network from scratch. However, the number of param-\n",
    "eters are too large to be trained properly with such few number of images provided.\n",
    "One solution is to shift the learned weights in a way to perform well on the test\n",
    "set, while preserving as much information as necessary from the training class.\n",
    "### In this Session, extract 5 classes from STL training dataset , \n",
    "the the label of images can be defined as `{1: 'airplanes',2:'birds',3:'ships',4:'cats',5:'dogs'}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *`Q3.1 create the STL10_Dataset `*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stl10_data import *\n",
    "class STL10_Dataset(Dataset):\n",
    "    def __init__(self,root,train=True,transform = None):\n",
    "        ################################\n",
    "        # Todo: finish the code\n",
    "        ################################\n",
    "\n",
    " \n",
    "\n",
    "    def __len__(self):\n",
    "        ################################\n",
    "        # Todo: finish the code\n",
    "        ################################\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        ################################\n",
    "        # Todo: finish the code\n",
    "        ################################\n",
    "\n",
    "        return img, target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *`Q3.2  Finetuning from ConvNet & train the model and show the results`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Todo: finish the code\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  `Bonus`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
